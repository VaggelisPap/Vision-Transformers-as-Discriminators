{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_inpaintings = load_dataset(\"imagefolder\", data_dir=\"./inpaintings_dataset\")\n",
    "dataset_style_transfer = load_dataset(\"imagefolder\", data_dir=\"./style_transfer_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 7120\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 3006\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_inpaintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 4913\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 1235\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_style_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import torch\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"VaggP/convnext-tiny-finetuned-for-inpaintings-in-art-detection\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"VaggP/convnext-tiny-finetuned-for-inpaintings-in-art-detection\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "def transform(batch):\n",
    "    # Take a list of PIL images and turn them to pixel values\n",
    "    inputs = image_processor([x for x in batch['image']], return_tensors='pt')\n",
    "\n",
    "    # Don't forget to include the labels!\n",
    "    inputs['label'] = batch['label']\n",
    "    return inputs\n",
    "\n",
    "dataset_inpaintings = dataset_inpaintings.with_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['label'] for x in batch])\n",
    "    }\n",
    "\n",
    "dataloader_test_inpaintings = DataLoader(dataset_inpaintings[\"test\"], collate_fn=collate_fn, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdda417d15d24aa2839ff7ee036b8e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8410\n",
      "Precision: 0.7616\n",
      "Recall: 0.9927\n",
      "F1 Score: 0.8619\n",
      "Confusion Matrix:\n",
      "[[1036  467]\n",
      " [  11 1492]]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "all_predicted = []\n",
    "all_labels = []\n",
    "\n",
    "for idx, batch in enumerate(tqdm(dataloader_test_inpaintings)):\n",
    "    batch = {k:v.to(device) for k,v in batch.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values=batch[\"pixel_values\"], labels=batch[\"labels\"])\n",
    "\n",
    "    loss, logits = outputs.loss, outputs.logits\n",
    "\n",
    "    predicted = logits.argmax(-1)\n",
    "    correct += (predicted == batch[\"labels\"]).sum().item()\n",
    "    total += batch[\"labels\"].shape[0]\n",
    "\n",
    "    all_predicted.extend(predicted.cpu().numpy())\n",
    "    all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "\n",
    "accuracy = correct/total\n",
    "\n",
    "precision = precision_score(all_labels, all_predicted)\n",
    "recall = recall_score(all_labels, all_predicted)\n",
    "f1 = f1_score(all_labels, all_predicted)\n",
    "\n",
    "labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']\n",
    "conf_matrix = confusion_matrix(all_labels, all_predicted)\n",
    "\n",
    "plt.show()\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"VaggP/convnext-tiny-finetuned-for-style-transfer-in-art-detection\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"VaggP/convnext-tiny-finetuned-for-style-transfer-in-art-detection\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "dataset_style_transfer = dataset_style_transfer.with_transform(transform)\n",
    "\n",
    "dataloader_test_style_transfer = DataLoader(dataset_style_transfer[\"test\"], collate_fn=collate_fn, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4e2241b38446feb090ba45f9d7a5d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9895\n",
      "Precision: 0.9882\n",
      "Recall: 0.9899\n",
      "F1 Score: 0.9890\n",
      "Confusion Matrix:\n",
      "[[635   7]\n",
      " [  6 587]]\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "all_predicted = []\n",
    "all_labels = []\n",
    "\n",
    "for idx, batch in enumerate(tqdm(dataloader_test_style_transfer)):\n",
    "    batch = {k:v.to(device) for k,v in batch.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values=batch[\"pixel_values\"], labels=batch[\"labels\"])\n",
    "\n",
    "    loss, logits = outputs.loss, outputs.logits\n",
    "\n",
    "    predicted = logits.argmax(-1)\n",
    "    correct += (predicted == batch[\"labels\"]).sum().item()\n",
    "    total += batch[\"labels\"].shape[0]\n",
    "\n",
    "    all_predicted.extend(predicted.cpu().numpy())\n",
    "    all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "\n",
    "accuracy = correct/total\n",
    "\n",
    "precision = precision_score(all_labels, all_predicted)\n",
    "recall = recall_score(all_labels, all_predicted)\n",
    "f1 = f1_score(all_labels, all_predicted)\n",
    "\n",
    "labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']\n",
    "conf_matrix = confusion_matrix(all_labels, all_predicted)\n",
    "\n",
    "plt.show()\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
